#### Introduction

- Local Search : A local search data structure stores a number of elements each with a key coming from an ordered set. It supports operations.
- RangeSearch(x,y): Returns all elements with keys between x and y
- NearestNeighbors(z): Returns the element with keys on either size of z
- Insert(x): Adds a element with key x
- Delete(x): Removes the element with key x.

- Hash Table : Insert and delete are O(1), But RangeSearch & NearestNeighbors are impossible.
- Array : RangeSearch & NearestNeighbors are O(n), Insert O(1), delete(1)
- Sorted array: RangeSearch & NearestNeighbors are O(log(n)), Insert and Delete are O(n)
- Linked list : RangeSearch & NearestNeighbors are O(n), Insert O(1), delete(1)

#### Search Trees

- Rarts of a tree : Root node, left subtree smaller keys, right subtree bigger keys.
- Tree node data type: key, parent, left child, right child

#### Basic Operations

````

Find(Key k, Root r)
output: The node in the tree of R with the key k

Find(k, R)
    if R.key == k:
        return R
    else if R.key > k:
        return Find(k, R.Left)
    else if R.key < k:
        return Find(k, R.Right)
````

- Missing key: If you stop before reaching a null pointer, you find the place in the tree where k would fit.

```
Find(k, R)
    if R.key == k:
        return R
    else if R.key > k:
        if R.left != null:
            return Find(k, R.Left)
        return R
    else if R.key < k:
        if R.right != null:
            return Find(k, R.Right)
        return R
````

- Adjacent Elements : Given a node N in a BST would like to find adjacent elements.

```
Next(Node n)
Output: The node in the tree with the next largest key.


Next(n)
    if n.right != null:
        return LeftDesendant(n.right)
    else:
        return RightAncestor(n)
        
LeftDescendant(n)
    if n.left = null
        return n
    else:
        return LeftDescendant(n.left)
        
RightAncestor(n)
    if n.key < n.parent.key
        return n.parent
    else:
        return RightAncestor(n.parent)
```


- Range Search

```
RangeSearch 
input: numbers x,y, root R
output: A list of nodes with key between x and y


RangeSearch(x,y,R)
    l = []
    n = Find(x, R)
    while n.key <= y
        if n.key >= x:
            l = l.append(n)
        n = next(n)
    return l
            

Insert(Key k, root R)
Output: Adds node with key k to the tree.

Insert(k, R)
    P = Find(k, R)
    add new node with key k as child of P


Remove(Node N)
output: Remove node N from the tree

Delete(n)
    if n.right = null:
        remove N, promote n.left
    else:
        x = next(n)
        // x.left = null
        Replace n by x, promote x.right

```


#### Balance

- Want left and right subtrees to have approximately the same size
- Suppose perfectly balanced.
- Each subtree half the size of its parent.
- After log2(n) levels, subtree of size 1.
- Operation run in 0(log(n)) time
- Rearrange tree to maintain balance. How do we rearrange tree while maintaining order? Rotation!


```
RotateRight(x)
    p = x.parent
    y = x.left
    b = y.right
    y.parent = p
    p.appropriatechild = y
    x.parent = y, y.right = x
    b.parent = x, x.left = b

```

#### AVL Trees

- Want to maintain balanece.
- Need a way to measure balance.
- Height : the height of a node is the maximum depth of its subtree.
- n.height equals 1 if n is a left, 1 + max(n.left.height, n.right.height)

- Height is a rough measure of subtree size.
- Want size of subtrees roughly the same.
- Force heights to be roughly the same.

- AVL trees maintain the following property: For all nodes N, |N.left.height - N.right.height| <= 1. We claim that this ensures balance.
- Need to show that AVL property implies height = O(log(n)), Alternatively, show that large height implies many nodes.


#### AVL Tree Implementation

- Heights stay the same except on the insertion path.Only need to worry about this path.

```
AVLInsert(k, R)
    insert(k, R)
    n = find(k, R)
    Rebalance(n)
    
Rebalance(n)
    p = n.parent
    if n.left.height > n.right.height + 1:
        rebalanceRight(n)
    if n.right.height > n.left.height + 1:
        rebalanceLeft(n)
    AdjustHeight(n)
    if p != null:
        rebalance(p)
        
AdjustHeight(n)
    n.height = 1 + max(n.left.height, n.right.height)
    
RebalanceRight(n)
m = n.left
if m.right.height > m.left.right:
    rotateLeft(m)
rotateRight(n)
Adjustheight on affected nodes.


AVLDelete(n)
    delete(n)
    m = parent of node replacing n
    Rebalance(m)
```

- Deletions can also change balance


#### Split and Merge

- Another useful feature of BST is the ability to recombine them in interesting ways.
- Merge : Combines two BST into a single one
- Split : Breaks one BST into two.

```
Merge
input: root r1 and r2 of trees with all keys in r1's tree smaller than those in r2's
outout: the root of a new tree with all the elements of both trees.

MergeWithRoot(r1, r2, t)
    t.left = r1
    t.right = r2
    r1.parent = t
    r2.parent = t
    return t

Merge(r1,r2)
    t = find(infinite, r1)
    delete(t)
    mergewithroot(r1, r2, t)
    return t

```

- get new root by removing largest element of left subtree.
- Unfortunately, This merge does not preserve balance properties.
- go down side of tree until merge with subtree of same height.


```
AVLTreeMergeWithRoot(r1,r2,t)
    if |r1.height - r2.height| <= 1:
        mergeWithRoot(r1,r2,t)
        t.height = max(r1.height. r2.height) + 1
    return t
    else if r1.height > r2.height:
        r3 = AVLTreeMWR(r1,right, r2, t)
        r1.right = r3
        r3.parent = r1
        Rebalance(r1)
        return root
    else if r1.height < r2.height:
    (...)

```

- Split : Break tree into two trees.
```
Split(Root r of a tree, key k)
output: two trees, one with elements <x , one with elements > x.
```

- Search for x, merge subtrees.
```
Split(r,x)
    if r = null:
        return null, null
    if x < r.key:
        (r1, r2) = split(r.left, x)
        r3 = mergeWitrhRoot(r2, r.right, r)
        return (r1, r3)
    if x > r.key
    (...)
    
```
